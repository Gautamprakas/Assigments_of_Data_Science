{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b90e81d-8c63-4476-8fe2-a0dd238e0ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "Answer-Web scraping is used in a variety of digital businesses that rely on data harvesting. Legitimate \n",
    "use cases include: Search engine bots crawling a site, analyzing its content and then ranking it. Price \n",
    "comparison sites deploying bots to auto-fetch prices and product descriptions for allied seller websites.\n",
    "Thre major areas are Marketing,Bussiness,Analyst.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1f83ba-9476-4c55-81fd-125cd9b0b667",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q2. What are the different methods used for Web Scraping?\n",
    "Anser-These are the tools that is used in web scrapping\n",
    "BrightData\n",
    "Scrape.do\n",
    "Scrapingdog\n",
    "AvesAPI\n",
    "ParseHub\n",
    "Diffbot\n",
    "Octoparse\n",
    "ScrapingBee\n",
    "Grepsr\n",
    "Scraper API\n",
    "Scrapy\n",
    "Import.io'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16259679-007b-4808-9c09-45e35c2e11f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q3. What is Beautiful Soup? Why is it used?\n",
    "Answer-Beautiful Soup provides simple methods for navigating, searching, and modifying a parse tree in HTML,\n",
    "XML files. It transforms a complex HTML document into a tree of Python objects. It also automatically \n",
    "converts the document to Unicode, so you don't have to think about encodings.'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273e77d3-e6b4-4647-bfde-15870b149314",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q4. Why is flask used in this Web Scraping project?\n",
    "Answer-Flask is a lightweight framework to build websites. We'll use this to parse our collected data \n",
    "and display it as HTML in a new HTML file. The requests module allows us to send http requests to the \n",
    "website we want to scrape. The first line imports the Flask class and the render_template method from the \n",
    "flask library.24'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef76bf85-b43b-4b0b-b006-6cd142be034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "Anser-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
